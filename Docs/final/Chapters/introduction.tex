\pagestyle{mypagestyle}

\setcounter{page}{1}
\pagenumbering{arabic}

\cleardoublepage
\chapter{Introduction}
\label{chap:intro}
%\lhead{Chapter \ref{chap:intro}. \emph{\nameref{chap:intro}}} % This is for the header
\vspace{-15pt}
In recent years, there has been a large increase in the amount and availability of geographic data which has prompted a similar rise on the number of applications to capture, store, manipulate and analyse this data.
A lot of these applications share the need to visualise the geographic information in such a way that it can be easily understood by a human.
This is usually done by displaying points of interest on a map so that their relative position and distribution can be easily interpreted by the user.

One obstacle when representing large amounts of geographic data is that the sheer number of points to display can be overwhelming for a human, as well as computationally intensive to render for a machine. As such, there is a need to develop and implement a viable way to reliably calculate and display a subset of geographic points, whilst keeping a degree of representativeness of the larger set.

The purpose of SGP-GIMS, a QREN-funded project that involves the University of Coimbra and \emph{Smartgeo}, is to research and develop a real-time algorithm that can analyse geographic data provided by a geographic information system (GIS) infrastructure developed and maintained at Smartgeo. More precisely, the developed algorithm must be able to aggregate and select geographic points according to a given a set of criteria. Figure \ref{fig:rep} shows a large set of geographic points and an example of a representative subset.

\input{Figures/rep}

This thesis aims to design and and analyse different algorithms that allow to choose a representative subset of geographic points, whilst being able to dynamically change that set of points via zooming or panning over a geographic region containing a large amount of geographical data. 
The algorithm that is deemed the most suitable to solve the task is integrated in a web framework via the \emph{geojson} and \emph{WFS} (web feature service) geographic data communication standards. The application is meant to function as an independent module capable of being decoupled and used for different clients and/or servers. Figure \ref{fig:arch} shows the basic concept of the architecture for the web application.

\input{Figures/arch}

Some well-known web applications and services perform similar operations that already select points from large sets. Currently, there are two ways of handling the problem: to preprocess the data into layers of representation, and to project the points into a limited resolution image format.

Most of these applications rely on having different preprocessed layers of information, which contain similarly ranked points. For example, a map of a continent would only request the layer containing the capitals of the visible countries, whilst a map of a singular country would only request the layer containing the cities within the viewing window's coordinates. This solution requires that a lot of preprocessed data be stored in a fairly large and robust database. It also skips the representation problem by having points with different importance ranks. If any geographic query returns too many points for the application to render, then it could choose to only display the higher ranked ones or, alternatively, repeat the same query to the layer above to reduce the number of points to be rendered. Since this project requires that no storage space is used, other solutions must be found.

In the second approach of projecting all points to a limited resolution image format, mapping vectorial points into a bitmap format with no aliasing means that all points that are closer together than a pixel are likely be rounded off to the same spot, effectively merging the two points. Explicitly creating an image file may result in a larger file, which may cause problems in a bandwidth-dependent web application. The solution to this would be to round the coordinates of every point to a grid, and only relay the coordinates of the grid that would contain any points. This method, however, would mean a loss of precision increasing with the size of the grid. Furthermore, the points selected would be grid-aligned, and not necessarily correspond with any of the original, vectorial set. This would make for a visual pattern, which would be obvious for a human user. This solution is therefore also not suitable for our purpose.

Since none of the two approaches were suitable for the project, particular algorithms were developed to properly solve the problem. The first approach interpreted the representation problem as an optimization problem known as \emph{$k$-centre} \cite{facilityloc}. This problem consists of finding $k$ points from a large set that optimizes a given measure of representation, namely coverage. The cardinality constraint means that the number of representative points must be known before the algorithm is ran, which is not always possible. Because of this particular limitation, and coupled with performance issues, a second approach was considered: the coverage distance is established a priori and the goal is to find the smallest set of points such that no point in the set is uncovered. This is known as a \emph{Geometric Disk Cover} \cite{gdccomplex} problem, and our specific formulation has one extra constraint: each disk has it centre on a point of the original set. This problem was solved using an approximation algorithm, which compromises the quality of the result (within a controlled threshold) in order to be performed in a more reasonable time. 

This report is organized as follows:
Chapter \ref{chap:theory} defines the base theoretical concepts, such as a notion of representativeness, as well as some useful data structures used in the algorithms. Chapter \ref{chap:algos} describes the implicit enumeration algorithms implemented for the $k$-centre problem. The goal of this problem is to, given a set $N$ of $n$ points, find the subset of centroids of cardinality $k$ that minimises the farthest distance of a point in $N$ to its closest centroid. The chapter also contains an analysis their time and space complexities. Chapter \ref{chap:approx} describes an approximation algorithm for the geometric disk coverage problem. The goal of the geometric disk cover problem is to, given a set $N$ of points and a minimum distance $d$, find the smallest number $k$ of circles of radius $d$ centred around points in $N$ such that no point is left uncovered. The chapter also describes heuristic speed-ups and a space and time complexity analysis for the algorithms, and ends with a proposed solution to the issue of panning the viewing window. The work developed in this thesis was presented as a poster \cite{valenca} on the 18th International Conference on Geographic Information Systems, AGILE 2015.